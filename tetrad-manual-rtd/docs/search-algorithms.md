# Search Algorithms

Tetrad provides a wide range of causal discovery algorithms.  
This page gives a **curated, expert-guided overview** of the algorithms most users should try first.

For the full catalog‚Äîincluding specialized, legacy, and experimental methods‚Äîsee:

üëâ **[Full Algorithm List](search.algorithms.full)**

---

## üîç Choosing an Algorithm

Tetrad‚Äôs algorithms fall into two broad categories depending on whether you assume  
**no hidden confounders (DAG/CPDAG target)** or  
**possible hidden confounders (PAG target)**.

### **If you assume *no hidden confounders* (DAG target):**
Start with one of these:
- **FGES** ‚Äî fast, scalable, score-based default
- **BOSS** ‚Äî order-based; often finds sharper orientations
- **PC / PC-Max** ‚Äî constraint-based; explicitly tuned by Œ±

> GRaSP can provide complementary insight, but is not a first-line method.

---

### **If hidden confounders are possible (PAG target):**
Use one of:
- **FCI** ‚Äî canonical method for latent confounding / selection bias
- **BOSS-FCI** ‚Äî score-assisted hybrid improving precision
- **FCIT** ‚Äî targeted-testing hybrid; reduces spurious independences

RFCI is a speed-optimized alternative when FCI is too slow.

---

## üèÜ Recommended Algorithms (with descriptions)

These are the algorithms most users should consider first.

---

### **FGES ‚Äî Fast Greedy Equivalence Search**

**Type:** Score-based  
**Output:** CPDAG (assumes no hidden confounders)

FGES performs greedy hill-climbing over equivalence classes of DAGs using a penalized score (typically SEM-BIC). It is extremely fast and effective for medium to large datasets.

**When to use:**
- Continuous or discrete data
- No major latent confounding expected
- You want speed and a clear objective score

**Strengths:** Highly scalable, parallelizable, interpretable score.  
**Limitations:** Assumes causal sufficiency.

---

### **BOSS ‚Äî Best Order Score Search**

**Type:** Score-based  
**Output:** CPDAG

BOSS searches over **variable orders**, scoring parent sets consistent with each order. Often yields more decisive orientations than structure-only hill-climbing.

**When to use:**
- Same settings as FGES
- As a strong alternative or as the score engine for hybrids (e.g., FCIT, BOSS-FCI)

---

### **PC ‚Äî Peter‚ÄìClark Algorithm**

**Type:** Constraint-based  
**Output:** CPDAG

PC identifies adjacencies through conditional independence tests, then orients using standard PC rules.

**When to use:**
- You want explicit statistical control via Œ±
- CI test assumptions match your data

**Notable variant:** **PC-Max**, which improves orientation precision.

---

### **FCI ‚Äî Fast Causal Inference**

**Type:** Constraint-based  
**Output:** PAG (allows latents + selection bias)

FCI is the standard algorithm for discovering causal structure when unmeasured confounders or selection bias may be present.

**When to use:**
- You need a PAG
- Latent confounding is plausible

**Limitations:** Runs many CI tests; can be conservative or slow.

---

### **RFCI ‚Äî Really Fast Causal Inference**

**Type:** Constraint-based  
**Output:** PAG

RFCI uses more aggressive pruning than FCI, trading some completeness for significant gains in speed.

**When to use:**
- High-dimensional data
- FCI is too slow
- Preliminary latent-variable structure discovery

---

### **GFCI ‚Äî Greedy Fast Causal Inference**

**Type:** Hybrid (score + CI tests)  
**Output:** PAG

GFCI combines score-based search (e.g., FGES) with FCI-style pruning/orientation. Often the strongest general-purpose method for latent-variable cases.

**When to use:**
- Latent confounding expected
- You want higher precision/recall than FCI alone

---

### **BOSS-FCI ‚Äî BOSS-Score Hybrid for FCIs**

**Type:** Hybrid  
**Output:** PAG

Uses the BOSS score engine to propose a structure, followed by FCI-style testing and orientation. Often improves orientations and reduces false positives.

---

### **FCIT ‚Äî FCI with Targeted Testing**

**Type:** Hybrid  
**Output:** PAG

FCIT uses score information (typically from BOSS) to **prioritize CI tests**, avoiding many unnecessary or uninformative tests.

**When to use:**
- Medium‚Äìlarge datasets
- FCI/GFCI are slow or unstable
- You want a cleaner PAG with fewer spurious independences

---

## üéõ Choosing CI Tests & Scores

A quick rule-of-thumb:

- **Continuous Gaussian-ish:** Fisher Z test; SEM-BIC score
- **Discrete:** G-test or Chi-square; BDeu/BIC scores
- **Mixed / nonlinear:** KCI or RCIT (slower); basis-function methods may help
- **Covariance-only:** Use algorithms supporting covariance + N (e.g., FGES with SEM-BIC)

---

## ‚ö†Ô∏è Common Pitfalls

- **Too many edges:** Lower Œ± (constraint-based) or increase penalty (score-based)
- **Too few edges:** Raise Œ± or decrease score penalty
- **Odd orientations:** Try PC-Max or add minimal prior knowledge
- **Slow runtime:** Limit depth; try RFCI or FCIT; increase threads

---

## üìÑ Algorithm Parameters

All algorithm parameters are documented here:

üëâ [`parameter.definitions.md`](./parameter.definitions.md)

Machine-readable source:

üëâ [`parameter.definitions.txt`](./_static/manual/parameter.definitions.txt)